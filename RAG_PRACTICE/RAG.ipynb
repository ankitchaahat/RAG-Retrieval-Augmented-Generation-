{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edWkVGW-YhmC",
    "outputId": "5852f250-be2b-4ad8-fc02-57b6358407c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 649,
     "referenced_widgets": [
      "c3648bdb4007447a8899bbfbc923dcf8",
      "ca9b47373503446490091444a105cb08",
      "6e89ef2833ff4a338a7d14c1575da1df",
      "fddd82433a654bfc99223906b3d0ec06",
      "f7c0210e9b594c7e8cf5efb463937d08",
      "af6e8c06c4ff46b7bfb4a85048cea323",
      "fed05fe66bbf4151b5d0f0126ed9067f",
      "1c53d925ad514e08839c852e2b28161d",
      "48056580a2284e4099e8ad46bda93576",
      "5515e522ed0844c58ec28f24f9a7a7a6",
      "dcacd4052baf47faa067a747f0496c50",
      "4b25fefadbf845b4b5e8d5be044d645a",
      "eed9c19a9dd146bfaf976ee318d1832c",
      "595237fddc6546b3b0542fd3cbb6ee4f",
      "458aaf1e657e46319af4669f8e39e390",
      "585ee6aab54d44d4a8eadfb4c756b2d0",
      "bafbc203b7f04dd6a311bebf7205ef56",
      "308566cc26f444a3b9da7c169439dcda",
      "192602c4da384b3da9efd8a738596334",
      "370e60a2aaba4d15b058e1bc34df55d9",
      "5df1b3634c6044f6b5a6c8ae67d0dfba",
      "2f5689ceb6fa4790a6e854a40b3dd843",
      "df4da71c60fa4b6cadaa837c0e853167",
      "8c3376e790e243c6b131109cd7301d7e",
      "c367d8fcb9354fd2baa22a4ee7ede92b",
      "fb9bc6dbe0cf40149ce3eb91bfec48b9",
      "d55d2cad0a80457fab734e24f35bb296",
      "1fb6653f8ef346d3a9bedefd3d52f0d1",
      "ad9dc801628343859a299686dcba646b",
      "7101d7fad3a54f519399aa6ced306286",
      "286d5cda65d848568e4055f2635976a7",
      "7fc757385fbf47e9a496d8fd77058841",
      "01232bb197b7462eb05b9aa76046a6a5",
      "2d54812e28614cde8ee7fd997f1fb204",
      "2a3090d320a74f058ca2013e72432d67",
      "7a3cf85e7edb41309a96f96cb5398c85",
      "7332b204e2bb442381d4500d0d72e2cf",
      "1ba09f6431f2453f942e3dff7aa841ad",
      "f13b47c95c2342468b97e567a26ac974",
      "aaa780f63ecc4740a5c8be5e648036d0",
      "2f3c18d0d2d242608358521fd589315b",
      "510efb50976a4365a338e6d961c91585",
      "35aba33df25641518a0cee834f8d683f",
      "778e2491baa741d0ac7386210ca86845",
      "d0f83e04d4dc4731a1af844efb292573",
      "df579aac7cd744f5a876b43d18412563",
      "7316e4ffa66a4f50b6fba7434dc74958",
      "4017353528054649b08ac563a48cf7a6",
      "f9adb4b543e04276bfbaab66d5a52804",
      "29a5c3e888ae4cb0bbb827aab65b9e11",
      "5897b8bd4bb941138db7fb25e818da3f",
      "32376a1032cd45f493e8890692257007",
      "267a2abde9b148a8a3171db6f8f3effe",
      "435bf299c29a4cf085f9a412fe4d1e3e",
      "542a0afe1b064a23899ef464fa4cc286",
      "817d9a2ac7bc49c096d101fc7c31a210",
      "632d60030a8f4829ab5c2ad57bee4dbc",
      "3bdfc1fbd95e43ffba24577b30f634ca",
      "41800ce315f7404788e64c43e001cf4e",
      "c46665c7aa08494eb0eefc826bfd2275",
      "694ce3d0c0674c179a6033905ac10050",
      "13a0b7c511d842358820acae0ecac6f4",
      "21f14d6e719440be8a548bac68f5a0a4",
      "cff0bb0fd6424634b0109ec013619866",
      "45038b7c3f35442199e3016f93d63a05",
      "8aa94ca869454a0f9f2c8e4e02b41378",
      "9f11d4402324481d99b464d4bb39c16b",
      "33db315ab58c426a9d491f0cff692b13",
      "d6c73c42821a4281b1b55f49af1fe4c4",
      "25eb141845594384bb538a3886946e91",
      "4dccecb693804d8c9e26961f84ead114",
      "01dd06715d3d4c7ca3a437dcc417361f",
      "f94f6237a7ec4ddb99870789b868aab2",
      "e68a6879a0bf4507b285418c2205e2ef",
      "4634283a1296474abaa60ae749956c58",
      "7e07ec4f3ea54907b5619b31d3ca944a",
      "d4ce262416b8488a8d25e48c80ba2b67",
      "5d91bd2b51cd4d4db227a6f199ea26ac",
      "af28b865831b4f048e125ce448d19711",
      "0489c1717dce4bb2bd26f1784a3e395c",
      "26d785f7e8f44ae7ac43911ac3dc1301",
      "577ea313f7504142823a4a4da2550cf5",
      "4fe61d301f1149e88cef4c9b3df48e59",
      "f047460a12fb482380c0a30067d69801",
      "b9d21dc89f2e4a3d91aa2c6b74fafb01",
      "12b00da9c2f742e8811b5b61a57ce9e6",
      "274f60b2a593495a89249bb9146398e1",
      "980f804e333744719ce353101130eb4e",
      "f98cfde6be6f4dd3b0ff8213f8474b75",
      "a0579340e3864a178e0b4e4fdf3155e3",
      "275c042c82474a28acf90e082da6f746",
      "d802c237b25440ae8ce03fefbcfa1f09",
      "0b13bdbd46fd4a1c919c25ddaff074ac",
      "3c8e877516de4c34a11d2e3fcd7c04ef",
      "91b534d0571b4d20beae25418a7bf694",
      "10e0cce3e95e4b7e8cabff8313bfe59f",
      "0e7f991965b6440089424cf914449784",
      "0b276c9ed62b42cf8ef7bfcbf868a627",
      "3521571225f44af89c6c94d6d325362b",
      "d675cb192bd14be7bca296bf00559159",
      "eaa015a752a14906a748f749bb3c4b9d",
      "525b01adab3543d18c38fc8695da0fc3",
      "0e6e4f71ca62409ba76c130feee31297",
      "9d83c77d17e048f7bb994051a4871c7f",
      "850714e88a094ed2916ab67a4ddb2423",
      "fef08b3ca964440483a924fc527b01e9",
      "427ea8be8a0f4e5eb38c339e3c5d61b8",
      "839d846f70a34dd59b51ece1d4731251",
      "aa3320ee75bc48239613044a9785ba28",
      "e3f5af32792049a3a6af950b29b49012",
      "3afb84a1cae7486581d174ab923d1e95",
      "3262f5a2d2344a13908634ab86879d03",
      "20a0f6ea6d3a4a5dbdc0441a81d83002",
      "cb3ed35f62aa47ba9d5d855e7f0bb61f",
      "47901cf10c4547d0b09953f2e014bf3c",
      "6c504018c8ed433180645766e84f3417",
      "a020801d5c0343fe91da9b2c071e0e3e",
      "6e253958fa264c108ce400d5f294091f",
      "ad43c54f5b204e0aa706706bc57c69e2",
      "b93d73c87cf94efc996328478242794e",
      "736d80af2d914609bfca3903ee9b6507"
     ]
    },
    "id": "c3qknkR3Y4ro",
    "outputId": "62e7b19a-7460-4827-e73f-62b972971ca9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3648bdb4007447a8899bbfbc923dcf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b25fefadbf845b4b5e8d5be044d645a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df4da71c60fa4b6cadaa837c0e853167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d54812e28614cde8ee7fd997f1fb204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f83e04d4dc4731a1af844efb292573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817d9a2ac7bc49c096d101fc7c31a210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f11d4402324481d99b464d4bb39c16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d91bd2b51cd4d4db227a6f199ea26ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98cfde6be6f4dd3b0ff8213f8474b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d675cb192bd14be7bca296bf00559159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3afb84a1cae7486581d174ab923d1e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved: OpenAI's CEO is Sam Altman\n"
     ]
    }
   ],
   "source": [
    "# Ensure faiss-cpu is installed\n",
    "!pip install faiss-cpu\n",
    "\n",
    "# Now import the necessary libraries\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "docs = [\"OpenAI's CEO is Sam Altman\", \"India's AI mission is AIRAWAT\", \"Python is a programming language\"]\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "doc_embeddings = model.encode(docs, convert_to_tensor=False)\n",
    "query = \"Who is the CEO of OpenAI?\"\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "index = faiss.IndexFlatL2(len(query_embedding))\n",
    "index.add(np.array(doc_embeddings))\n",
    "D, I = index.search(np.array([query_embedding]), k=1)\n",
    "\n",
    "print(\"Retrieved:\", docs[I[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thPYNjgdZKe_",
    "outputId": "625cd944-7397-4eaa-a18b-9acbd8e8a247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved: Python is a programming language\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "docs = [\"OpenAI's CEO is Sam Altman\", \"India's AI mission is AIRAWAT\", \"Python is a programming language\"]\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "doc_embeddings = model.encode(docs, convert_to_tensor=False)\n",
    "query = \"What is python?\"\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "index = faiss.IndexFlatL2(len(query_embedding))\n",
    "index.add(np.array(doc_embeddings))\n",
    "D, I = index.search(np.array([query_embedding]), k=1)\n",
    "\n",
    "print(\"Retrieved:\", docs[I[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhwBEi4dZSRE",
    "outputId": "b8e8b15d-67ab-4aaf-e77b-9a55ed871b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved: India's AI mission is AIRAWAT\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "docs = [\"OpenAI's CEO is Sam Altman\", \"India's AI mission is AIRAWAT\", \"Python is a programming language\"]\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "doc_embeddings = model.encode(docs, convert_to_tensor=False)\n",
    "query = \"What is indias mission?\"\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "index = faiss.IndexFlatL2(len(query_embedding))\n",
    "index.add(np.array(doc_embeddings))\n",
    "D, I = index.search(np.array([query_embedding]), k=1)\n",
    "\n",
    "print(\"Retrieved:\", docs[I[0][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIOm8CkrbNcP",
    "outputId": "19fd9c78-1d0a-4cea-ebd2-3b16963794c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 1 Score: 0.7071\n",
      "Doc 2 Score: 0.0000\n",
      "Doc 3 Score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "docs = [\n",
    "    \"OpenAI developed GPT models\",\n",
    "    \"Jersey cows give good quality milk\",\n",
    "    \"India launched AIRAWAT AI mission\"\n",
    "]\n",
    "\n",
    "query = \"Tell me about OpenAI and GPT\"\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "doc_vectors = vectorizer.fit_transform(docs)\n",
    "query_vector = vectorizer.transform([query])\n",
    "\n",
    "scores = cosine_similarity(query_vector, doc_vectors)\n",
    "\n",
    "for i, score in enumerate(scores[0]):\n",
    "    print(f\"Doc {i+1} Score: {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716,
     "referenced_widgets": [
      "6dda0f6e7d7d4fe78857eb323fe8fb81",
      "605e292449534aa7aea942bd4e1650a5",
      "8f6eb11d105c4b059b39a596d2bca22d",
      "db2f7a57a2ee420f895479d84d6a5fbb",
      "3dc15df2cc2c4bbbb4809c13ad18f701",
      "554241f3bbd3413faa531a7003fda7d6",
      "9fa040d4472849aaa63c6fa08a15dca0",
      "52cc51fb537247c6a30ebcaced82b3f7",
      "174191644f6347fca73427424a556acc",
      "e38e7080f83842bbac41a021d70605ba",
      "7e30d3d766484df18b0a5a8eeef2ba17",
      "abc0514b0d7241f2acf472df7c4f6783",
      "886e4cb32b4e43fc9de82e3e0e2da39c",
      "7163ff6bcc0a4f3ca6c0e3ac41a63556",
      "e81fcaa2de354492a25013c2df283962",
      "4a05e1265f74457da6d80feb5ab4cc6e",
      "9173df07d5954916b8f223c88fb6e857",
      "1e38ff36984b4bc5968a6419b6625f15",
      "9d1c8d67b32c4e6898cf3c775c3ed0ad",
      "ddc7a01f8ced49e4859a68cc417ded3f",
      "ddc3f6d9e9904629b3939ed049a7df91",
      "47c80d338e2342a5ac6833e5ee727b76",
      "74430ce6edec48b8a7ea5166663f9e9c",
      "04c6feff59ca48cb9d99946334db573d",
      "cce3fc1784f7407a8498696153d44f86",
      "2fa2d98ad934422b94ae9db57298f791",
      "960e16e3d20344c89ccd90e592ee905c",
      "39fc9b4869814a218138b7269f7aa272",
      "83bc49942cdc4dd39ed1394aee8b87fb",
      "99aaf58062ff4c85823b177e39dcc84a",
      "af7455cd5b5f4173b343c70f8b8a1dbd",
      "b9687bbd10524d85a1bef7574d74d741",
      "f8600a42a233450e90896f001ba44705",
      "fa587504f77a4835bbd2e37e8c6d56df",
      "e7ce0f45f6714a10885030e92d08d3ef",
      "c0ca308aa35c44e9bd77488158502bcb",
      "1f39dc823757434a8ddc77d8a76fa6d4",
      "16f1fe28963748d8b580183be8878ac8",
      "c87d7de68cfd47429cd927fe5d17136e",
      "ad5bdbc46c9f466da20b40e037fa846e",
      "d717d4aadae04287a8f0e44af0312a2a",
      "9f7816a15f8f4d9fa7a43cf809d870bd",
      "7f9dfcdb90c94d1ab17726f2d025ed6a",
      "72e5f2b0d9704430b283517ff4f6809e",
      "1d50642ba66a4490bbe9961f49ceb1eb",
      "22b4d28951ea46d5adbac7edd34afb58",
      "2a58d553b03b4e88906406930a5b55a8",
      "99e56436cce34c5698284a18a39297c8",
      "679618a976084a8d9a7f8c6183adda33",
      "cac094a61e91402dbeb2d2bdf98414d8",
      "dcc5c7acc899441496930c463675f059",
      "9e227e3db7484466bb028940d7fe1211",
      "2bb84f6d22fd440d975ffff6318f0311",
      "e52e262874f6466ea34d4f0b8bdceb58",
      "ef67480d23f5441fb936a11a19bbcf14",
      "b367a83af62b447f9d0988ad8ce3a887",
      "3f049d08a44647e3959a7b9684090953",
      "8a21ecd3562f47409a73ac432557f36a",
      "bb63927541e247cd808e4da786b716a1",
      "f7b673491b2944f7928d3a99021df0af",
      "800d423c06d648ca81855abe86cdb3b3",
      "da54f0748f2d4363b17e9a38e737f16c",
      "e23430b5aee94ef797d636ba7fa147c2",
      "ccede9a42b2d4139b2a23d46c3b94b7b",
      "3c95847cbb844b78bb67c2953c6f9cff",
      "5569ae2413e8409ab27e2cc20872dbc0",
      "d6baf25da80e4934845fb2be6fa2baa3",
      "f0a3fe9903f4482cb8b1d677a2488c7d",
      "06a39810fc2343eda93e143fccf2c0f4",
      "42dfddb19f4645c4bd64fcf273513c6b",
      "16f1c2090b284e6e9350b7bf8b83528f",
      "dfa7574c2ec44497812c5902f946391b",
      "ea0bd8b7f94746b383eb05c2335ae111",
      "542982922db545de864797dd10d2498f",
      "bdfebb33641448c094ba41117e6f7f41",
      "457c9f058cdc4db48b83470869f08374",
      "23325d87ab0d4d369004dc06007fee0c",
      "c43b3ed6bc684036b20a9aa8ce69acf6",
      "f97c7ec478a041c4a9888d2ed0c6f161",
      "2de321c5779747639d4daef70c2383c4",
      "e9553f10af77465c8adf815ed6fc3c8b",
      "60d7ce1cca8744fc902441223c84a887",
      "026f8214adc84d28b463ced828bababe",
      "536f1962bff84ac79d83d6cd4b5e71f6",
      "75c8da57713b4ceda88cda961042cd7c",
      "1211a32207d3407ea5e808c2213ed973",
      "f2f7ee8ea2e04649a84075223958c770",
      "74adb0e864134f32aafedba9220e2ff9",
      "3e0d1245045a44e69101b49ea5af35d3",
      "0804f1a2d6e04b3c8c5be0985b0a1905",
      "c4757a2ff8ac40d28593c9567721e4aa",
      "7b1bbc93fa7c4fb29922631f3f96d3b2",
      "397c7e99fc864d9f94c72d44a710cc96",
      "9409fa9296b047ee903f0b67c5fe8ad5",
      "9f53660b393e427e81d26c4165db6bed",
      "08a43751384042af80020a3e423a1ae1",
      "f52352fbe386448e91df79c7a3bf2014",
      "1132d64d3d744fe3adc9e7067d7928eb",
      "19921c870ca84355b430d32169bd0d92",
      "3f35de8d366c4f2fa20ac9f9c4321860",
      "78705dbd86b14596a5a0c0aaf96e4dda",
      "95ee1c68a574425d9d1e53389fad3d43",
      "b805da2220154c94be92b635e3164522",
      "91869bf946904726ae197d9440b6e0e4",
      "d4337822d74f431d873fec8ec0740edb",
      "2633489cc2f14c1ebe9417c45ec4255b",
      "1c0e14096a80419ca07bc489318c96fc",
      "2ddbdf656dd24bdbae7d9dc332b60d62",
      "d178b748f28e42a692a262ccc47e8890",
      "cf64fe9270184a06a546bb367c493ba9",
      "0d191ecef8c74c54897751d5f649e2c4",
      "c3134a1708774ae992007f44e19a0052",
      "ce8da48e18614cb4ad41cac34df6780e",
      "d0cc8fc927b74f1897f7cbad7091ff87",
      "6df0ae09ff614482bc6896d6351000c0",
      "52be32cf44ec4457b5cfb4fa7472d7ce",
      "c37bd18d6916494583c4d044ddffce04",
      "6df031da98a84d34b941505022a834ab",
      "84e2804af77d47e681433c39dc2ab59f",
      "3df468ea0d314e9892526c1b51a73305",
      "36640391385845f8ac18e1dd4e8963c5",
      "498acd4994034e7b8f2d2fa7f0c5bc65",
      "7353ed643b1a44ed92c0311e0ab1706a",
      "1947f6a9be814657840448036e8a8ef6",
      "3681ec547a304cb283e0fb1bc14cca04",
      "f84fd2c3b85145bc8a6217daf52047bb",
      "71e62935b5a34ab7a0a3001703f75783",
      "d0cea1166620469aa21397ba4f4f4c6d",
      "f079402cfa7541e18dc8f2630bae00e2",
      "5e78944322284234a8069f0a3e007a29",
      "c899b8a57b8e443086724caf02f95d3d",
      "3ea5c5ff219949fe8c9a982be65617b1"
     ]
    },
    "id": "pSYJMgjombhj",
    "outputId": "6a9959a2-6ce3-4a96-82d1-607b46363c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total Chunks: 44635\n",
      "üöÄ Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dda0f6e7d7d4fe78857eb323fe8fb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc0514b0d7241f2acf472df7c4f6783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74430ce6edec48b8a7ea5166663f9e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa587504f77a4835bbd2e37e8c6d56df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d50642ba66a4490bbe9961f49ceb1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b367a83af62b447f9d0988ad8ce3a887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6baf25da80e4934845fb2be6fa2baa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c43b3ed6bc684036b20a9aa8ce69acf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0d1245045a44e69101b49ea5af35d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f35de8d366c4f2fa20ac9f9c4321860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d191ecef8c74c54897751d5f649e2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498acd4994034e7b8f2d2fa7f0c5bc65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîé Score: 0.3553\n",
      "üìÑ Chunk: in my room after breakfast tomorrow will you Yes father Your hands are rather cold Louisa Are you not well Quite well father And cheerful She looked at him again and smiled in her peculiar manner I am as cheerful father as I usually am or usually have been Thats well said Mr Gradgrind So he kissed her and went away and Louisa returned to the serene apartment of the haircutting character and leaning her elbow on her hand looked again at the shortlived sparks that so soon subsided into ashes Are you there Loo said her brother looking in at the door He was quite a young gentleman of pleasure now and not quite a prepossessing one Dear Tom she answered rising and embracing him how long it is since you have been to see me Why I have been otherwise engaged Loo in the evenings and in the\n",
      "\n",
      "üîé Score: 0.3454\n",
      "üìÑ Chunk: and terrible event. By very slow degrees, and with frequent relapses that alarmed and grieved my friend, I recovered. I remember the first time I became capable of observing outward objects with any kind of pleasure, I perceived that the fallen leaves had disappeared and that the young buds were shooting forth from the trees that shaded my window. It was a divine spring, and the season contributed greatly to my convalescence. I felt also sentiments of joy and affection revive in my bosom; my gloom disappeared, and in a short time I became as cheerful as before I was attacked by the fatal passion. ‚ÄúDearest Clerval,‚Äù exclaimed I, ‚Äúhow kind, how very good you are to me. This whole winter, instead of being spent in study, as you promised yourself, has been consumed in my sick room. How shall I ever repay you? I feel the greatest remorse for\n",
      "\n",
      "üîé Score: 0.3273\n",
      "üìÑ Chunk: forth from the trees that shaded my window It was a divine spring and the season contributed greatly to my convalescence I felt also sentiments of joy and affection revive in my bosom my gloom disappeared and in a short time I became as cheerful as before I was attacked by the fatal passion Dearest Clerval exclaimed I how kind how very good you are to me This whole winter instead of being spent in study as you promised yourself has been consumed in my sick room How shall I ever repay you I feel the greatest remorse for the disappointment of which I have been the occasion but you will forgive me You will repay me entirely if you do not discompose yourself but get well as fast as you can and since you appear in such good spirits I may speak to you on one subject may I\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ STEP 1: Chunking Function\n",
    "def chunk_text(text, chunk_size=150, overlap=30):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "# ‚úÖ STEP 2: Load File (adjust path if needed)\n",
    "with open(\"/content/conversation_chatgpt.txt\", \"r\", encoding=\"cp1252\") as f:\n",
    "    full_text = f.read()\n",
    "\n",
    "chunks = chunk_text(full_text)\n",
    "print(f\"‚úÖ Total Chunks: {len(chunks)}\")\n",
    "\n",
    "# ‚úÖ STEP 3: Load Model and Move to GPU\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"üöÄ Using device:\", device)\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=device)\n",
    "\n",
    "# ‚úÖ STEP 4: Encode chunks on GPU\n",
    "chunk_embeddings = model.encode(\n",
    "    chunks,\n",
    "    convert_to_tensor=True,\n",
    "    device=device,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# ‚úÖ STEP 5: Encode query and search\n",
    "from sentence_transformers import util\n",
    "\n",
    "query = \"How are you?\"\n",
    "query_embedding = model.encode(\n",
    "    query,\n",
    "    convert_to_tensor=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# ‚úÖ STEP 6: Cosine similarity\n",
    "scores = util.cos_sim(query_embedding, chunk_embeddings)[0]\n",
    "\n",
    "# ‚úÖ STEP 7: Show top-k results\n",
    "top_k = 3\n",
    "top_chunks = scores.topk(top_k)\n",
    "\n",
    "for score, idx in zip(top_chunks.values, top_chunks.indices):\n",
    "    print(f\"\\nüîé Score: {score:.4f}\")\n",
    "    print(f\"üìÑ Chunk: {chunks[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404,
     "referenced_widgets": [
      "7661bd1faf604c07b0e7e8750b81e03a",
      "4e81765ee5034c6a939d6361308c77be",
      "5a88444f7584419da21ab0e05fcdb8b2",
      "b3fdfe909526413c9067b89bf9b5b200",
      "d8ab46fefdd042998782bf640385c443",
      "3491ffbcbd7146a68037e3eea78b7e70",
      "356d0290cbaf4bd0b35fbbb33f65ca01",
      "180da1613f2e48a58c82b1b801316393",
      "f606b804f3744b15b28bdaccb45d0657",
      "acb14fb5b620428c99eb095c9de0671b",
      "98ea1134b01a48d3b84396b3fbfebc94",
      "e48314c82ff345b6b74c11a2c65081f1",
      "af0dbe8a3324425fa085de302836ac24",
      "45b1cb497f194916aba2446009571e70",
      "e338f480fd9e4fd4b788adbf1e9cdcd1",
      "d0cf3da776ac449d9264f94e381bc2ab",
      "8b72fc0d993e4bddaf3f18fa50cf2811",
      "659ef1ebaa4b484b9fd9dc9d0781ad26",
      "1e215e0875474e69b65df1d9ff2716cf",
      "40825b894ab64ee19fb46bcd8822e318",
      "ce4d3942930f42cf8559d1b554933ba5",
      "1f60ec78f9af4d1b89897ab8929ad1fd",
      "4d0e3bf7a14f432e9d5dc1ed185b357b",
      "43a0debaffd545e4a69180f44c50f20f",
      "969d68c85efc42b3a2158c816087ac09",
      "3b623238a2c04ba1a8a13739d6cbdd40",
      "e85bf14fe503473a9504eab05e02f376",
      "44ff3074850849f0bb0b1c500a65201e",
      "f276bd6f27854acfbfad55161273e876",
      "1a218059d41c43f4bdb5b77cda8b2c6e",
      "92bf7a25f42a459d90dfe9ee8da53b11",
      "0fe9e084b99640bfacc9aef66a2f7d01",
      "465530a8783e44a4870c889f2952dbb7",
      "903f6bfe7a2b491999da4599d313e738",
      "143bbe1068744cb88e5365cfa7cffb90",
      "24afe42b76684dd09c11b8f80638e045",
      "91909a37d2d84806872a5b9aa5050cf8",
      "100de247fba34c798bef767c115564ff",
      "89ac2d40637745948c2eeed354f0617e",
      "d36fa5098a664103bd8e2275415b977b",
      "9d362d4f4b104373b4f99b3c6ebba2e2",
      "79ddb0f2edf34e8e9f4ea8b34c83e1a2",
      "ae2bdff6f44244caa401dfe0b0b392b9",
      "f47234903c9242ff9c4c05a5ca40e54a",
      "383a39fcf9c246e8bf77b9e1b93fb486",
      "c27799fa543c438485047d35043ee6a1",
      "054b63c0690648ecba5e78206dad12ad",
      "3750a82b5fea49dfaffd3c7277a1733e",
      "39a3ed32dfae4237875a0821648ee4a7",
      "a208df0ceb114607b1aff9bd94eb2827",
      "c0294d1a98e54a7b9a7465ecfe215685",
      "30022ebb875a4fcc87073573a434d38d",
      "9a547475c43647d48e49fc327aa3a890",
      "242dda03a3764ec8a36d9c0e2cb3c480",
      "b83056bd891a41318adfc2b3e323bd08",
      "4018628419c1456e9f55bf254c30c9fb",
      "4686ccafc6c746ad83b8d3d26e43eb3f",
      "b162625a50ad40d2bfd7678a39329952",
      "611934bc054341c3a3d0cbb0425e5a11",
      "9628a0cdb6d54562813b3292e6b0f152",
      "db74c6bdb19146689571cc927553b251",
      "fbcabb538f7e42d58fcaca0139e94c19",
      "7e7258298265459e81e1e26f369abe3b",
      "e6e9a44715a847fd9bfb95a6fbb93e26",
      "02014906857d48c4b605f349fc4ae7ca",
      "709808cf278340049740601f5019e4d0",
      "e50333f7bfc54972b63075a4b012b1be",
      "b494ce604da840a4994caafcf5582670",
      "6249f937f7064e069c2cef9066be939d",
      "51d8b266ddd4448ead9042ce5d3a9746",
      "5bb1c1ef556e446fbca0db432d74c7ee",
      "a41ce37eb7084441a4a6839f297fc78c",
      "018fc0dd17d641c892c7b0787765d384",
      "808dee8acc0e42d791f8f89da9cce37c",
      "2f91b47d4028419687e1cb454300394c",
      "1901790ce4ea4d928cdeaf22d139c372",
      "39527cd2156242f8956bfa37cff1ec62",
      "2d8d91c6219445e79a9ce26d4d4a3b64",
      "45ffab2aff3548dc96838f80a09ea137",
      "3256ce9b60dc461f8b313a2c21d080e2",
      "bca853a4212043dd8065e6bcfb83f3d4",
      "936518b4f0be4389b581898606eaae66",
      "734caad733934561be3640cc39a79ed8",
      "13e18db778a74fda9dab68b95bb97ecd",
      "03e2e66a828a409281040e233e6cbcde",
      "82f1c95238a04bceb1363fb12cf768bc",
      "4e9cf19d2b5646d5945749ffba3c653b",
      "8057851c092a4277a249e7977d242edb",
      "ce589b73abd54fa08572bba0a0556a4b",
      "1cf6fd3b24b54a028023adf2acfb8403",
      "da4604c36a1242b4b275fb6b5c7fbf9d",
      "e8d8be2fe07b4adf94a75c73b174150e",
      "6a644b86b51c4447860643c0791636c7",
      "dc375d2270c74e0b9be4758836fe14e0",
      "b35c9976574543a3a50b7bb79b349def",
      "1316a27d66d44d558582442ee3eedac5",
      "810a08d85853452b85dfb760c63920cf",
      "23518424ef0d4b50a5c63ced4c0a873f",
      "e24ac897c1b242faa2e7c3f2f55f073c",
      "9fcc312ddb3446f39e5b73d4e7e2fca0",
      "cbbbc5c65ef7451fa68d803283cb3e49",
      "d10626b5fec54d45939f73242156d26c",
      "5f536cce9d42404a98b7ffe5c758067d",
      "10c11478cdfd46e99a2b7273bbbb11fe",
      "08feb31e369a40b1b9c950d06b4dcb66",
      "055f8de77d534413b972d402c756dc54",
      "22366590e38a40e29e06a5242c3f790c",
      "753da5863c4241299dbd62e977f5a6a8",
      "1f36aae3f5014a0da5d8a994dfcfa220",
      "3a9dfee8ddab4602854617372fc5a731",
      "e1b629dbec0747919b7f4b3d792f99b0",
      "06465d22b81549aabaf13b89209ae85b",
      "f0bca4c16f4b473b969d4b6ab540b7c5",
      "e78baf219af84e78b12cd60595f81f33",
      "a4d0eee6802c4febb527a8b0da0e4f87",
      "a9eea32457684e91887b724ad3f91040",
      "d7152aeec6494a51af60985c109e996f",
      "6c3766b902834134accc562a3cc55b00",
      "616a459f10694635a858dda91e41fd83",
      "3bf449318d184281b12692f8124a5b1c",
      "6be9778d6f2e4555bc49bc08de159570"
     ]
    },
    "id": "9B3U8coBnlUa",
    "outputId": "767dc561-9815-4503-cad9-5fe07b49f924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7661bd1faf604c07b0e7e8750b81e03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e48314c82ff345b6b74c11a2c65081f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/67.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0e3bf7a14f432e9d5dc1ed185b357b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903f6bfe7a2b491999da4599d313e738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383a39fcf9c246e8bf77b9e1b93fb486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4018628419c1456e9f55bf254c30c9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50333f7bfc54972b63075a4b012b1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d8d91c6219445e79a9ce26d4d4a3b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce589b73abd54fa08572bba0a0556a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fcc312ddb3446f39e5b73d4e7e2fca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total Chunks: 44635\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b629dbec0747919b7f4b3d792f99b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1395 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# ‚úÖ Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"üöÄ Using device:\", device)\n",
    "\n",
    "# ‚úÖ Load model\n",
    "model = SentenceTransformer(\"intfloat/e5-large-v2\")  # Better contextual awareness\n",
    "\n",
    "\n",
    "# ‚úÖ Chunking function\n",
    "def chunk_text(text, chunk_size=150, overlap=30):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "# ‚úÖ Load text file once\n",
    "with open(\"/content/conversation_chatgpt.txt\", \"r\", encoding=\"cp1252\") as f:\n",
    "    full_text = f.read()\n",
    "\n",
    "chunks = chunk_text(full_text)\n",
    "print(f\"‚úÖ Total Chunks: {len(chunks)}\")\n",
    "\n",
    "# ‚úÖ Encode all chunks once\n",
    "chunk_embeddings = model.encode(\n",
    "    chunks, convert_to_tensor=True, device=device, show_progress_bar=True\n",
    ")\n",
    "\n",
    "# ‚úÖ Create a retrieval function\n",
    "def ask_question(query_text):\n",
    "    query_embedding = model.encode(query_text, convert_to_tensor=True, device=device)\n",
    "    scores = util.cos_sim(query_embedding, chunk_embeddings)[0]\n",
    "    top_score, top_index = torch.max(scores, dim=0)\n",
    "\n",
    "    if top_score < 0.5:\n",
    "        print(f\"\\n‚ö†Ô∏è Low confidence (score: {top_score:.4f}). Showing top 3 matches:\")\n",
    "        top_k = 3\n",
    "        top_chunks = scores.topk(top_k)\n",
    "        for score, idx in zip(top_chunks.values, top_chunks.indices):\n",
    "            print(f\"\\nüîé Score: {score:.4f}\")\n",
    "            print(f\"üìÑ Chunk:\\n{chunks[idx]}\")\n",
    "    else:\n",
    "        print(f\"\\nü•á Top Match Score: {top_score:.4f}\")\n",
    "        print(f\"üìÑ Retrieved Chunk:\\n{chunks[top_index]}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbG-ns0YqkZ7"
   },
   "source": [
    "# USE YOUR OWN **DATASET** ABOVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j-VqM4RynsJj",
    "outputId": "7e483395-a1c9-4103-ce3e-098768218632"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü•á Top Match Score: 0.8446\n",
      "üìÑ Retrieved Chunk:\n",
      "AI has become in our daily lives? Absolutely! It‚Äôs incredible how AI has evolved, especially in areas like voice assistants, recommendation systems, and even healthcare. It feels like every day, there‚Äôs a new AI-powered tool that makes life easier. Right, and what amazes me is how seamlessly AI fits into our routines now. I mean, I remember when voice assistants like Siri and Alexa were just novelties, and now they‚Äôre pretty much indispensable. I know, right? And it‚Äôs not just the voice assistants. AI is helping doctors detect diseases faster, improving car navigation systems, and even predicting weather patterns more accurately. The potential is limitless. For sure. But it does make me wonder about the future. How far will AI go? Will it start making decisions that impact our lives in ways we can‚Äôt even predict yet? That‚Äôs a great question. I think AI is becoming more autonomous, especially with\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Example ‚Äî Just Change This Line!\n",
    "your_question = \"can you tell me about AI and its future?\"\n",
    "ask_question(your_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ta7zsu_abPWu",
    "outputId": "bdfd51f0-75e6-4811-baf5-2022a060f5a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü•á Top Match Score: 0.8231\n",
      "üìÑ Retrieved Chunk:\n",
      "alternate versions of yourself, or changing history is both thrilling and confusing. Do you think time travel is possible? According to some theories in physics, it might be possible under certain conditions, like with wormholes or extreme speeds close to the speed of light. But we have no practical way of achieving it yet. If you could travel to any point in time, where would you go? I think I‚Äôd visit the distant future, maybe 500 years from now, to see how humanity has evolved and what kinds of advancements we‚Äôve made. What‚Äôs your take on the idea of parallel universes? It‚Äôs a fascinating concept. The idea that there could be infinite versions of our universe, with slight or major differences, opens up endless possibilities. Each decision we make could create a new timeline somewhere. Do you think there could be a universe where things are radically different from our\n"
     ]
    }
   ],
   "source": [
    "your_question = \"Do you know time travel?\"\n",
    "ask_question(your_question)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
